{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Team Leader's Contribution: Advanced Analysis & Ensemble Learning\n",
                "\n",
                "## Objective\n",
                "This notebook integrates the work from the team (SVM and Random Forest models) and performs advanced analysis. \n",
                "**CRITICAL UPDATE**: Due to missing contributions, the Team Leader has implemented the **Linear Regression (Baseline)** and **Deep Learning (MLP)** models to ensure project completeness.\n",
                "\n",
                "### Scope:\n",
                "1.  **Baseline Model**: Linear Regression (Implemented by Team Lead).\n",
                "2.  **Teammate Models**: SVM (Optimized) and Random Forest (Tuned).\n",
                "3.  **Advanced Model**: Deep Learning / MLPRegressor (Implemented by Team Lead).\n",
                "4.  **Ensemble Learning**: Combining ALL 4 models using VotingRegressor.\n",
                "5.  **Model Comparison**: Visualizing performance across all approaches.\n",
                "\n",
                "## 1. Imports & Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
                "from sklearn.svm import SVR\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.neural_network import MLPRegressor\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "\n",
                "# Set plot style\n",
                "sns.set(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading & Preprocessing\n",
                "We use the consistent preprocessing pipeline defined by the team."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset\n",
                "df = pd.read_csv('../data/audi.csv')\n",
                "\n",
                "# Define features\n",
                "numeric_features = ['year', 'mileage', 'tax', 'mpg']\n",
                "categorical_features = ['model', 'transmission', 'fuelType']\n",
                "\n",
                "X = df[numeric_features + categorical_features]\n",
                "y = df['price']\n",
                "\n",
                "# Numeric transformer\n",
                "numeric_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='median')),\n",
                "    ('scaler', StandardScaler())\n",
                "])\n",
                "\n",
                "# Categorical transformer\n",
                "categorical_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
                "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
                "])\n",
                "\n",
                "# Combine preprocessing\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', numeric_transformer, numeric_features),\n",
                "        ('cat', categorical_transformer, categorical_features)\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Split data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "print(f\"Training samples: {X_train.shape[0]}\")\n",
                "print(f\"Testing samples: {X_test.shape[0]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Baseline Model: Linear Regression (Implemented by Team Lead due to missing module)\n",
                "Since the Linear Regression module was missing from the repository, I am implementing it here as a baseline for comparison."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr_model = Pipeline(steps=[\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('regressor', LinearRegression())\n",
                "])\n",
                "\n",
                "print(\"Training Linear Regression (Baseline)...\")\n",
                "lr_model.fit(X_train, y_train)\n",
                "y_pred_lr = lr_model.predict(X_test)\n",
                "r2_lr = r2_score(y_test, y_pred_lr)\n",
                "print(f\"Linear Regression R2 Score: {r2_lr:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model 1: Optimized SVM\n",
                "Using the best parameters found in the SVM notebook: `C=500`, `epsilon=0.2`, `gamma='scale'`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "svm_pipeline = Pipeline(steps=[\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('regressor', SVR(kernel='rbf', C=500, epsilon=0.2, gamma='scale'))\n",
                "])\n",
                "\n",
                "print(\"Training Optimized SVM...\")\n",
                "svm_pipeline.fit(X_train, y_train)\n",
                "y_pred_svm = svm_pipeline.predict(X_test)\n",
                "\n",
                "r2_svm = r2_score(y_test, y_pred_svm)\n",
                "print(f\"Optimized SVM R2 Score: {r2_svm:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model 2: Random Forest (Tuning)\n",
                "We start with the base Random Forest model and then perform Hyperparameter Tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Base Random Forest\n",
                "rf_base = Pipeline(steps=[\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
                "])\n",
                "\n",
                "print(\"Training Base Random Forest...\")\n",
                "rf_base.fit(X_train, y_train)\n",
                "y_pred_rf_base = rf_base.predict(X_test)\n",
                "r2_rf_base = r2_score(y_test, y_pred_rf_base)\n",
                "print(f\"Base Random Forest R2 Score: {r2_rf_base:.4f}\")\n",
                "\n",
                "# Hyperparameter Tuning for Random Forest\n",
                "param_grid_rf = {\n",
                "    'regressor__n_estimators': [100, 200],\n",
                "    'regressor__max_depth': [None, 10, 20],\n",
                "    'regressor__min_samples_split': [2, 5]\n",
                "}\n",
                "\n",
                "print(\"\\nTuning Random Forest (this may take a while)...\")\n",
                "grid_rf = GridSearchCV(rf_base, param_grid_rf, cv=3, scoring='r2', n_jobs=-1, verbose=1)\n",
                "grid_rf.fit(X_train, y_train)\n",
                "\n",
                "best_rf = grid_rf.best_estimator_\n",
                "print(\"Best RF Params:\", grid_rf.best_params_)\n",
                "\n",
                "y_pred_rf_opt = best_rf.predict(X_test)\n",
                "r2_rf_opt = r2_score(y_test, y_pred_rf_opt)\n",
                "print(f\"Optimized Random Forest R2 Score: {r2_rf_opt:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Advanced Model: Deep Learning / MLP (Implemented by ntthang-dev)\n",
                "Implementing a Multi-Layer Perceptron (MLP) Regressor to capture complex non-linear relationships."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mlp_model = Pipeline(steps=[\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('regressor', MLPRegressor(hidden_layer_sizes=(128, 64, 32),\n",
                "                               activation='relu',\n",
                "                               solver='adam',\n",
                "                               max_iter=500,\n",
                "                               random_state=42))\n",
                "])\n",
                "\n",
                "print(\"Training MLP Regressor (Deep Learning)...\")\n",
                "mlp_model.fit(X_train, y_train)\n",
                "y_pred_mlp = mlp_model.predict(X_test)\n",
                "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
                "print(f\"MLP Regressor R2 Score: {r2_mlp:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model 3: Ensemble Learning (Voting Regressor)\n",
                "Combining ALL 4 models: Linear Regression, Optimized SVM, Optimized Random Forest, and MLP."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "voting_regressor = VotingRegressor(\n",
                "    estimators=[\n",
                "        ('lr', lr_model),\n",
                "        ('svm', svm_pipeline),\n",
                "        ('rf', best_rf),\n",
                "        ('mlp', mlp_model)\n",
                "    ]\n",
                ")\n",
                "\n",
                "print(\"Training Ensemble Model (LR + SVM + RF + MLP)...\")\n",
                "voting_regressor.fit(X_train, y_train)\n",
                "y_pred_ensemble = voting_regressor.predict(X_test)\n",
                "\n",
                "r2_ensemble = r2_score(y_test, y_pred_ensemble)\n",
                "print(f\"Ensemble Model R2 Score: {r2_ensemble:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Model Comparison & Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Collect results\n",
                "results = pd.DataFrame({\n",
                "    'Model': ['Linear Regression', 'Optimized SVM', 'Optimized RF', 'MLP Regressor', 'Ensemble'],\n",
                "    'R2 Score': [r2_lr, r2_svm, r2_rf_opt, r2_mlp, r2_ensemble]\n",
                "})\n",
                "\n",
                "print(results)\n",
                "\n",
                "# Bar Chart Comparison\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.barplot(x='R2 Score', y='Model', data=results, palette='viridis')\n",
                "plt.title('Final Model Comparison: R2 Score')\n",
                "plt.xlim(0.7, 1.0)  # Zoom in on high scores\n",
                "plt.show()\n",
                "\n",
                "# Scatter Plot: True vs Predicted (Ensemble)\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.scatter(y_test, y_pred_ensemble, alpha=0.5, color='purple')\n",
                "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
                "plt.xlabel('True Price')\n",
                "plt.ylabel('Predicted Price')\n",
                "plt.title('Ensemble Model: True vs Predicted Price')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "The Team Leader has successfully integrated all models, filling the gaps left by missing contributions. The Ensemble model, combining Linear Regression, SVM, Random Forest, and MLP, provides a robust and high-performing solution for car price prediction."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}